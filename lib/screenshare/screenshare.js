/*
 * Lucas Fialho Zawacki
 * Paulo Renato Lanzarin
 * (C) Copyright 2017 Bigbluebutton
 *
 */

'use strict'

const C = require('../bbb/messages/Constants');
const MediaHandler = require('../media-handler');
const Utils = require('../utils/Utils.js');
const Messaging = require('../bbb/messages/Messaging');
const Logger = require('../utils/Logger');
const BaseProvider = require('../base/BaseProvider');
const config = require('config');
const errors = require('../base/errors');
const localIpAddress = config.get('localIpAddress');
const EventEmitter = require('events').EventEmitter;
const SHOULD_RECORD = config.get('recordScreenSharing');
const KEYFRAME_INTERVAL = config.get('screenshareKeyframeInterval');
const ENABLE_SCREENSHARE_FLASH_BRIDGE = config.has('screenshareEnableFlashRTPBridge')
  ? config.get('screenshareEnableFlashRTPBridge')
  : false;
const DEFAULT_MEDIA_SPECS = config.get('conference-media-specs');
const SUBSCRIBER_SPEC_SLAVE = config.has('videoSubscriberSpecSlave')
  ? config.get('videoSubscriberSpecSlave')
  : false;
const KURENTO_REMB_PARAMS = config.util.cloneDeep(config.get('kurentoRembParams'));
const SCREENSHARE_PLAY_START_ENABLED = config.has(`screensharePlayStartEnabled`)
  ? config.get(`screensharePlayStartEnabled`)
  : false;
const SCREENSHARE_SERVER_AKKA_BROADCAST = config.has(`screenshareServerSideAkkaBroadcast`)
  ? config.get(`screenshareServerSideAkkaBroadcast`)
  : true;

const LOG_PREFIX = "[screenshare]";

// Global MCS endpoints mapping. These hashes maps IDs generated by the mcs-core
// lib to the ones generate in the ScreenshareManager
let sources = {};
let rtpEndpoints = {};

module.exports = class Screenshare extends BaseProvider {
  constructor(id, bbbGW, voiceBridge, userId, vh, vw, meetingId, mcs, hasAudio) {
    super(bbbGW);
    this.sfuApp = C.SCREENSHARE_APP;
    this.mcs = mcs;
    this.presenterMCSUserId;
    this.userId = userId;
    this._connectionId = id;
    this._presenterEndpoint = null;
    this._ffmpegEndpoint = null;
    this._voiceBridge = voiceBridge;
    this._meetingId = meetingId;
    this._streamUrl = "";
    this._vw = vw;
    this._vh = vh;
    this._presenterCandidatesQueue = [];
    this._viewerUsers = {};
    this._viewerEndpoints = [];
    this._viewersCandidatesQueue = [];
    this._status = C.MEDIA_STOPPED;
    this._rtmpBroadcastStarted = false;
    this.recording = {};
    this.isRecorded = false;
    this._recordingSubPath = 'screenshare';
    this._startRecordingEventFired = false;
    this._stopRecordingEventFired = false;
    this.hasAudio = hasAudio;
    this.handleMCSCoreDisconnection = this.handleMCSCoreDisconnection.bind(this);
    this.mcs.on(C.MCS_DISCONNECTED, this.handleMCSCoreDisconnection);
  }

  _getPartialLogMetadata () {
    return {
      roomId: this._voiceBridge,
      internalMeetingId: this._meetingId,
      status: this._status,
    };
  }

  _getFullPresenterLogMetadata (connectionId) {
    return {
      ...this._getPartialLogMetadata(),
      userId: this.presenterMCSUserId,
      mediaId: this._presenterEndpoint,
      connectionId,
      role: `presenter`,
      hasFlashRTMPBridge: !!this._ffmpegEndpoint,
    };
  }

  _getFullViewerLogMetadata (connectionId) {
    const { userId } = this._viewerUsers[connectionId] || {};
    const mediaId = this._viewerEndpoints[connectionId];
    return {
      ...this._getPartialLogMetadata(),
      userId,
      mediaId,
      connectionId,
      role: `viewer`,
    };
  }

  /* ======= ICE HANDLERS ======= */

  async onIceCandidate (candidate, role, userId, connectionId) {
    switch (role) {
      case C.SEND_ROLE:
        if (this._presenterEndpoint) {
          try {
            this.flushCandidatesQueue(this.mcs, [...this._presenterCandidatesQueue], this._presenterEndpoint);
            this._presenterCandidatesQueue = [];

            await this.mcs.addIceCandidate(this._presenterEndpoint, candidate);
          } catch (error) {
            Logger.error(LOG_PREFIX, `ICE candidate could not be added to media controller due to ${error.message}.`,
              { ...this._getFullPresenterLogMetadata(connectionId), error });
          }
        } else {
          this._presenterCandidatesQueue.push(candidate);
          Logger.debug(LOG_PREFIX, `Pushing ICE candidate to presenter queue`,
            this._getFullPresenterLogMetadata(connectionId));
        }
      case C.RECV_ROLE:
        let endpoint = this._viewerEndpoints[connectionId];
        if (endpoint) {
          try {
            this.flushCandidatesQueue(this.mcs, [...this._viewersCandidatesQueue[connectionId]], endpoint);
            this._viewersCandidatesQueue[connectionId] = [];

            await this.mcs.addIceCandidate(endpoint, candidate);
          } catch (error) {
            Logger.error(LOG_PREFIX, `ICE candidate could not be added to media controller due to ${error.message}.`,
              { ...this._getFullViewerLogMetadata(connectionId), error });
          }
        } else {
          this._viewersCandidatesQueue[connectionId] = [];
              this._viewersCandidatesQueue[connectionId].push(candidate);
          Logger.debug(LOG_PREFIX, `Pushing ICE candidate to viewer queue`,
            this._getFullViewerLogMetadata(connectionId));
        }
        break;
      default:
        Logger.warn(LOG_PREFIX, "Unknown role", role);
      }
  }

  _onMCSIceCandidate (event, connectionId, endpoint) {
    const { mediaId, candidate } = event;
    if (mediaId !== endpoint) {
      return;
    }
    const isPresenter = this.connectionId === connectionId;
    const logMetadata = isPresenter
      ? this._getFullPresenterLogMetadata(connectionId)
      : this._getFullViewerLogMetadata(connectionId);

    Logger.debug(LOG_PREFIX, `Received ICE candidate from mcs-core`,
      { ...logMetadata, candidate });

    this.bbbGW.publish(JSON.stringify({
      connectionId,
      type: C.SCREENSHARE_APP,
      id : 'iceCandidate',
      candidate : candidate
    }), C.FROM_SCREENSHARE);
  }

  /* ======= MEDIA STATE HANDLERS ======= */

  _onPresenterWebRTCMediaFlowing (connectionId) {
    Logger.info(LOG_PREFIX, `Presenter WebRTC session is FLOWING`,
        this._getFullPresenterLogMetadata(connectionId));
    if (!this._rtmpBroadcastStarted) {
      // Checking if transcoder is avaiable; if so, transposes the stream to RTMP
      this._startRtmpBroadcast(this._meetingId);
      if (this._status != C.MEDIA_STARTED) {
        if (this.isRecorded) {
          this.startRecording();
        }
        this._status = C.MEDIA_STARTED;
        this.sendPlayStart(C.SEND_ROLE, connectionId);
      }
    }
  };

  _onPresenterWebRTCMediaNotFlowing (connectionId) {
    Logger.warn(LOG_PREFIX, `Presenter WebRTC session is NOT_FLOWING`,
      this._getFullPresenterLogMetadata(connectionId));
    // TODO properly implement a handler when we have a client-side reconnection procedure
  }

  sendPlayStart (role, connectionId) {
    if (SCREENSHARE_PLAY_START_ENABLED) {
      this.bbbGW.publish(JSON.stringify({
        type: C.SCREENSHARE_APP,
        id : 'playStart',
        connectionId,
        role,
      }), C.FROM_SCREENSHARE);
    }
  }

  _onViewerWebRTCMediaFlowing (connectionId) {
    Logger.info(LOG_PREFIX, `Viewer WebRTC session is FLOWING`,
      this._getFullViewerLogMetadata(connectionId));
    const viewerUser = this._viewerUsers[connectionId];

    if (viewerUser && !viewerUser.started) {
      this.sendPlayStart(C.RECV_ROLE, connectionId);
      viewerUser.started = true;
    }
  }

  _onViewerWebRTCMediaNotFlowing (connectionId) {
    Logger.warn(LOG_PREFIX, `Viewer WebRTC session is NOT_FLOWING`,
      this._getFullViewerLogMetadata(connectionId));
    // TODO properly implement a handler when we have a client-side reconnection procedure
  }

  async _onRtpMediaFlowing () {
    if (!this._rtmpBroadcastStarted) {
      Logger.info(LOG_PREFIX, `Presenter RTP_TO_RTMP bridge session is FLOWING for the first time`,
        this._getFullPresenterLogMetadata(this.connectionId));
      const shouldHandleRtmpBridge = await this.bbbGW.isChannelAvailable(C.TO_BBB_TRANSCODE_SYSTEM_CHAN) && ENABLE_SCREENSHARE_FLASH_BRIDGE;
      const strm = Messaging.generateStartTranscoderRequestMessage(this._meetingId, this._meetingId, this._rtpParams);

      // Checking if transcoder is avaiable; if so, transposes the stream to RTMP
      if (shouldHandleRtmpBridge) {
        // Interoperability: capturing 1.1 start_transcoder_reply messages
        this.bbbGW.once(C.START_TRANSCODER_REPLY+this._meetingId, (payload) => {
          let meetingId = payload[C.MEETING_ID];
          let output = payload["params"].output;
          this._startRtmpBroadcast(meetingId, output);
        });

        // Capturing stop transcoder responses from the 2x model
        this.bbbGW.once(C.START_TRANSCODER_RESP_2x+this._meetingId, (payload) => {
          let meetingId = payload[C.MEETING_ID_2x];
          let output = payload["params"].output;
          this._startRtmpBroadcast(meetingId, output);
        });

        this.bbbGW.publish(strm, C.TO_BBB_TRANSCODE_SYSTEM_CHAN);
      } else {
        // transcoder is not available, pure WebRTC environment
        this._startRtmpBroadcast(this._meetingId);
      }

      if (this._status != C.MEDIA_STARTED) {
        if (this.isRecorded) {
          this.startRecording();
        }
        this._status = C.MEDIA_STARTED;
      }
    }
  };

  _onRtpMediaNotFlowing () {
    Logger.warn(LOG_PREFIX, `Presenter RTP_TO_RTMP bridge session is NOT_FLOWING`,
      this._getFullPresenterLogMetadata(this._connectionId));
  }

  _mediaStateRTP (event, endpoint) {
    const { mediaId, state } = event;
    if (mediaId !== endpoint) {
      return;
    }
    const { name, details = null } = state;
    switch (name) {
      case "MediaStateChanged":
        break;

      case "MediaFlowOutStateChange":
        Logger.debug(LOG_PREFIX, `RTP_TO_RTMP bridge session ${mediaId} received MediaFlowOut`,
          { ...this._getFullPresenterLogMetadata(this.connectionId), state });
        break;

      case "MediaFlowInStateChange":
        Logger.debug(LOG_PREFIX, `RTP_TO_RTMP bridge session ${mediaId} received MediaFlowIn`,
          { ...this._getFullPresenterLogMetadata(this.connectionId), state });
        if (details === 'FLOWING') {
          this._onRtpMediaFlowing();
        }
        else {
          this._onRtpMediaNotFlowing();
        }
        break;

      default: Logger.warn(LOG_PREFIX, "Unrecognized event", event);
    }
  }

  _handleIceComponentStateChange (state, logMetadata) {
    const { rawEvent } = state;
    const {
      componentId: iceComponentId,
      source: elementId,
      state: iceComponentState
    } = rawEvent;

    Logger.info(LOG_PREFIX, `Screenshare ICE component state changed`, {
      ...logMetadata,
      elementId,
      iceComponentId,
      iceComponentState
    });
  }

  _handleCandidatePairSelected (state, logMetadata) {
    const { rawEvent } = state;
    const { candidatePair, source: elementId } = rawEvent;
    const { localCandidate, remoteCandidate, componentID: iceComponentId } = candidatePair;
    Logger.info(LOG_PREFIX, `Screenshare new candidate pair selected`, {
      ...logMetadata,
      elementId,
      iceComponentId,
      localCandidate,
      remoteCandidate,
    });
  }

  _handleIceGatheringDone (state, logMetadata) {
    const { rawEvent } = state;
    const { source: elementId } = rawEvent;
    Logger.info(LOG_PREFIX, `Screenshare ICE gathering done`, {
      ...logMetadata,
      elementId,
    });
  }

  _handleMediaStateChanged (state, logMetadata) {
    const { rawEvent, details } = state;
    const { source: elementId } = rawEvent;
    Logger.info(LOG_PREFIX, `Screenshare media state changed`, {
      ...logMetadata,
      elementId,
      mediaState: details,
    });
  }

  _mediaStateWebRTC (event, endpoint, connectionId, flowingCallback, notFlowingCallback) {
    const { mediaId , state } = event;
    if (mediaId !== endpoint) {
      return;
    }
    const { name, details } = state;
    const isPresenter = connectionId === this._connectionId;
    const logMetadata = isPresenter
      ? this._getFullPresenterLogMetadata(connectionId)
      : this._getFullViewerLogMetadata(connectionId);

    switch (name) {
      case "IceComponentStateChange":
        this._handleIceComponentStateChange(state, logMetadata);
        break;
      case "NewCandidatePairSelected":
        this._handleCandidatePairSelected(state, logMetadata);
        break;
      case "IceGatheringDone":
        this._handleIceGatheringDone(state, logMetadata);
        break;
      case "MediaStateChanged":
        this._handleMediaStateChanged(state, logMetadata);
        break;
      case "MediaFlowOutStateChange":
      case "MediaFlowInStateChange":
        if (!ENABLE_SCREENSHARE_FLASH_BRIDGE || !isPresenter) {
          if (details === 'FLOWING') {
            flowingCallback(connectionId);
          }
          else {
            notFlowingCallback(connectionId);
          }
        }
        break;
      case C.MEDIA_SERVER_OFFLINE:
        if (isPresenter) {
          Logger.error(LOG_PREFIX, `Presenter WebRTC screensharing session received MEDIA_SERVER_OFFLINE event`,
            { ...logMetadata, event });
        } else {
          Logger.error(LOG_PREFIX, `Viewer WebRTC screensharing session received MEDIA_SERVER_OFFLINE event`,
            { ...logMetadata, event });
        }
        this.emit(C.MEDIA_SERVER_OFFLINE, event);
        break;
      default: Logger.warn(LOG_PREFIX, "Unrecognized event", event);
    }
  }

  _mediaStateRecording (event, endpoint) {
    const { mediaId , state } = event;
    if (mediaId !== endpoint) {
      return;
    }
    const { name, details } = state;

    switch (name) {
      case "MediaStateChanged":
        break;
      case "MediaFlowOutStateChange":
      case "MediaFlowInStateChange":
        Logger.info(LOG_PREFIX, `Recording media received media state event on endpoint ${endpoint}`,
          { ...this._getFullPresenterLogMetadata(this._connectionId), state });
        if (details === 'NOT_FLOWING' && this.status !== C.MEDIA_PAUSED) {
          Logger.warn(LOG_PREFIX, `Recording media STOPPED FLOWING on endpoint ${endpoint}`,
            this._getFullPresenterLogMetadata(this._connectionId));
        } else if (details === 'FLOWING') {
          if (!this._startRecordingEventFired) {
            const { timestampHR, timestampUTC } = state;
            this.sendStartShareEvent(timestampHR, timestampUTC);
          }
        }
        break;
      default: Logger.trace(LOG_PREFIX, "Unhandled recording event", event);
    }
  }

  /* ======= RECORDING METHODS ======= */

  async startRecording() {
    return new Promise(async (resolve, reject) => {
      try {
        const contentCodec = DEFAULT_MEDIA_SPECS.codec_video_content;
        const recordingProfile = (contentCodec === 'VP8' || contentCodec === 'ANY')
          ? this.hasAudio
            ? C.RECORDING_PROFILE_WEBM_FULL
            : C.RECORDING_PROFILE_WEBM_VIDEO_ONLY
          : this.hasAudio
            ? C.RECORDING_PROFILE_MKV_FULL
            : C.RECORDING_PROFILE_MKV_VIDEO_ONLY;
        const format = (contentCodec === 'VP8' || contentCodec === 'ANY')
          ? C.RECORDING_FORMAT_WEBM
          : C.RECORDING_FORMAT_MKV;
        const recordingPath = this.getRecordingPath(
          this._meetingId,
          this._recordingSubPath,
          this._voiceBridge,
          format
        );
        const recordingId = await this.mcs.startRecording(
          this.presenterMCSUserId,
          this._presenterEndpoint,
          recordingPath,
          { recordingProfile, ignoreThresholds: true, mediaProfile: 'content' }
        );
        this.recording = { recordingId, filename: recordingPath };
        this.mcs.onEvent(C.MEDIA_STATE, this.recording.recordingId, (event) => {
          this._mediaStateRecording(event, this.recording.recordingId);
        });
        resolve(this.recording);
      } catch (err) {
        reject(this._handleError(LOG_PREFIX, err));
      }
    });
  }

  sendStartShareEvent (timestampHR, timestampUTC) {
    const shareEvent = Messaging.generateWebRTCShareEvent('StartWebRTCDesktopShareEvent', this._meetingId, this.recording.filename, timestampHR, timestampUTC);
    this.bbbGW.writeMeetingKey(this._meetingId, shareEvent, function(error) {});
    this._startRecordingEventFired = true;
  }

  /* ======= STOP PROCEDURES ======= */

  start (sessionId, connectionId, sdpOffer, bbbUserId, role, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      this._status = C.MEDIA_STARTING;

      const isConnected = await this.mcs.waitForConnection();

      if (!isConnected) {
        return reject(errors.MEDIA_SERVER_OFFLINE);
      }

      // Probe akka-apps to see if this is to be recorded
      if (SHOULD_RECORD && role === C.SEND_ROLE) {
        this.isRecorded = await this.probeForRecordingStatus(this._meetingId, bbbUserId);
      }
      if (role === C.RECV_ROLE) {
        try {
          Logger.info(LOG_PREFIX, `Starting viewer screensharing session`,
            this._getFullViewerLogMetadata(connectionId));
          const sdpAnswer = await this._startViewer(
            connectionId,
            this._voiceBridge,
            sdpOffer,
            bbbUserId,
            this._presenterEndpoint,
            bbbUserName
          );
          return resolve(sdpAnswer);
        }
        catch (err) {
          return reject(this._handleError(LOG_PREFIX, err, role, bbbUserId));
        }
      }
      if (role === C.SEND_ROLE) {
        try {
          Logger.info(LOG_PREFIX, `Starting presenter screensharing session`,
            this._getFullPresenterLogMetadata(connectionId));
          const sdpAnswer = await this._startPresenter(sdpOffer, bbbUserId, bbbUserName);
          return resolve(sdpAnswer);
        }
        catch (err) {
          return reject(this._handleError(LOG_PREFIX, err, role, bbbUserId));
        }
      }
    });
  }

  _startPresenter (sdpOffer, userId, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      try {
        const presenterMCSUserId = await this.mcs.join(
          this._voiceBridge,
          'SFU',
          { externalUserId: userId, name: bbbUserName, autoLeave: true });
        this.presenterMCSUserId = presenterMCSUserId;
        const presenterSdpAnswer = await this._publishPresenterWebRTCStream(sdpOffer);
        await this.mcs.setContentFloor(this._voiceBridge, this._presenterEndpoint);
        resolve(presenterSdpAnswer);
      } catch (error) {
        Logger.error(LOG_PREFIX, `Error on starting screensharing presenter`,
          { ...this._getFullPresenterLogMetadata(this._connectionId), error });
        return reject(this._handleError(LOG_PREFIX, error));
      }

      if (ENABLE_SCREENSHARE_FLASH_BRIDGE) {
        try {
          await this._upstartRTPStream();
        } catch (error) {
          Logger.error(LOG_PREFIX, `Error on starting screensharing RTP_TO_RTMP bridge`,
            { ...this._getFullPresenterLogMetadata(this._connectionId), error });
        }
      }
    });
  }

  async _publishPresenterWebRTCStream (descriptor) {
    try {
      // Get the REMB spec to be used. Screenshare uses the default mixed in with
      // the default spec bitrate. Fetching bitrate by the VP8 codec is just an
      // arbitrary choice that makes no difference.
      // The media specs format isn't flexible enough, so that's what we have
      const kurentoRembParams = { ...KURENTO_REMB_PARAMS };
      kurentoRembParams.rembOnConnect = DEFAULT_MEDIA_SPECS.VP8.as_content;
      const options = {
        descriptor,
        name: this._assembleStreamName('publish', this.userId, this._voiceBridge),
        mediaProfile: 'content',
        kurentoRembParams,
      };
      const { mediaId, answer } = await this.mcs.publish(this.presenterMCSUserId, this._voiceBridge, C.WEBRTC, options);
      this._presenterEndpoint = mediaId;
      this.mcs.onEvent(C.MEDIA_STATE, this._presenterEndpoint, (event) => {
        this._mediaStateWebRTC(
          event,
          this._presenterEndpoint,
          this._connectionId,
          this._onPresenterWebRTCMediaFlowing.bind(this),
          this._onPresenterWebRTCMediaNotFlowing.bind(this)
        );
      });
      this.mcs.onEvent(C.MEDIA_STATE_ICE, this._presenterEndpoint, (event) => {
        this._onMCSIceCandidate(event, this._connectionId, this._presenterEndpoint);
      });
      sources[this._voiceBridge] = this._presenterEndpoint;
      const presenterSdpAnswer = answer;
      this.flushCandidatesQueue(this.mcs, [...this._presenterCandidatesQueue], this._presenterEndpoint);
      this._presenterCandidatesQueue = [];
      Logger.info(LOG_PREFIX, `Presenter WebRTC stream was successfully published`,
        this._getFullPresenterLogMetadata(this._connectionId));

      return presenterSdpAnswer;
    }
    catch (err) {
      // Handled in caller @_startPresenter
      throw err;
    }
  }

  async _fetchContentFloor () {
    try {
      const { floor } = await this.mcs.getContentFloor(this._voiceBridge);
      Logger.debug(LOG_PREFIX, `Content floor fetched`, { floor, ...this._getPartialLogMetadata()});
      return floor;
    } catch (e) {
      throw e;
    }
  }

  async _upstartRTPStream () {
    try {
      const sendVideoPort = MediaHandler.getVideoPort();
      const rtpSdpOffer = MediaHandler.generateVideoSdp(localIpAddress, sendVideoPort);
      const options = {
        descriptor: rtpSdpOffer,
        keyframeInterval: KEYFRAME_INTERVAL,
        mediaProfile: 'content'
      }

      if (this._presenterEndpoint == null) {
        const floor = await this._fetchContentFloor();
        this._presenterEndpoint = floor? floor.mediaId : null
      }

      const { mediaId, answer } = await this.mcs.subscribe(this.presenterMCSUserId,
        this._presenterEndpoint, C.RTP, options);
      this._ffmpegEndpoint = mediaId;
      rtpEndpoints[this._voiceBridge] = this._ffmpegEndpoint;
      const recvVideoPort = answer.match(/m=video\s(\d*)/)[1];
      const ipRegex = /(IP4\s)([0-9.]*)/g;
      const mediaServerIp = ipRegex.exec(answer)[2];
      this._rtpParams = MediaHandler.generateTranscoderParams(mediaServerIp, localIpAddress,
        sendVideoPort, recvVideoPort, this._meetingId, "stream_type_video",
        C.RTP_TO_RTMP, "copy", this.userId, this._voiceBridge);;
      this.mcs.onEvent(C.MEDIA_STATE, this._ffmpegEndpoint, (event) => {
        this._mediaStateRTP(event, this._ffmpegEndpoint);
      });
      Logger.info(LOG_PREFIX, `Presenter RTP_TO_RTMP bridge stream was successfully created`,
        { ...this._getFullPresenterLogMetadata(this._connectionId), mediaId: this._ffmpegEndpoint });
    } catch (err) {
      throw err;
    }
  }

  _startViewer(connectionId, voiceBridge, sdpOffer, userId, presenterEndpoint, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      let sdpAnswer;
      this._viewersCandidatesQueue[connectionId] = [];

      try {
        const mcsUserId = await this.mcs.join(
          this._voiceBridge,
          'SFU',
          { externalUserId: userId, name: bbbUserName, autoLeave: true });
        this._viewerUsers[connectionId] = {
          userId,
          connectionId,
          started: false,
        };

        // Get the REMB spec to be used. Screenshare uses the default mixed in with
        // the default spec bitrate. Fetching bitrate by the VP8 codec is just an
        // arbitrary choice that makes no difference.
        // The media specs format isn't flexible enough, so that's what we have
        const kurentoRembParams = { ...KURENTO_REMB_PARAMS };
        kurentoRembParams.rembOnConnect = DEFAULT_MEDIA_SPECS.VP8.as_content;
        const options = {
          descriptor: sdpOffer,
          name: this._assembleStreamName('subscribe', userId, this._voiceBridge),
          mediaProfile: 'content',
          mediaSpecSlave: SUBSCRIBER_SPEC_SLAVE,
          kurentoRembParams,
        }

        if (this._presenterEndpoint == null) {
          const floor = await this._fetchContentFloor();
          this._presenterEndpoint = floor? floor.mediaId : null
        }

        const { mediaId, answer } = await this.mcs.subscribe(mcsUserId,
          this._presenterEndpoint, C.WEBRTC, options);
        this._viewerEndpoints[connectionId] = mediaId;
        sdpAnswer = answer;
        this.flushCandidatesQueue(this.mcs, [...this._viewersCandidatesQueue[connectionId]], this._viewerEndpoints[connectionId]);
        this._viewersCandidatesQueue[connectionId] = [];
        this.mcs.onEvent(C.MEDIA_STATE, mediaId, (event) => {
          this._mediaStateWebRTC(
            event,
            mediaId,
            connectionId,
            this._onViewerWebRTCMediaFlowing.bind(this),
            this._onViewerWebRTCMediaNotFlowing.bind(this),
          );
        });
        this.mcs.onEvent(C.MEDIA_STATE_ICE, mediaId, (event) => {
          this._onMCSIceCandidate(event, connectionId, mediaId);
        });
        Logger.info(LOG_PREFIX, `Viewer WebRTC stream was successfully created`,
          this._getFullViewerLogMetadata(connectionId));

        return resolve(sdpAnswer);
      } catch (error) {
        Logger.error(LOG_PREFIX, `Viewer subscribe failed for ${userId} due to ${error.message}`,
          { ...this._getFullViewerLogMetadata(connectionId), error: this._handleError(LOG_PREFIX, error) });
        return reject(this._handleError(LOG_PREFIX, error));
      }
    });
  }

  _startRtmpBroadcast (meetingId, output) {
    if (SCREENSHARE_SERVER_AKKA_BROADCAST) {
      // If output is defined, we're using a RTMP url for the flash bridge
      // Else just pass the WebRTC stream name
      if (output) {
        this._streamUrl = MediaHandler.generateStreamUrl(localIpAddress, meetingId, output);
      } else {
        this._streamUrl = this._presenterEndpoint;
      }

      const timestamp = Math.floor(new Date());
      const dsrbstam = Messaging.generateScreenshareRTMPBroadcastStartedEvent2x(this._voiceBridge,
        this._voiceBridge, this._streamUrl, this._vw, this._vh, timestamp, this.hasAudio);
      this.bbbGW.publish(dsrbstam, C.TO_AKKA_APPS);
      this._rtmpBroadcastStarted = true;
      Logger.info(LOG_PREFIX, `Sent startRtmpBroadcast for ${meetingId}`,
        this._getPartialLogMetadata());
    }
  }

  /* ======= STOP PROCEDURES ======= */

  _sendStopShareEvent () {
    const timestampUTC = Date.now()
    const timestampHR = Utils.hrTime();
    const shareEvent = Messaging.generateWebRTCShareEvent('StopWebRTCDesktopShareEvent', this._meetingId , this.recording.filename, timestampHR, timestampUTC);
    this.bbbGW.writeMeetingKey(this._meetingId, shareEvent, function(error){});
    this._stopRecordingEventFired = true;
  }

  async _stopRecording () {
    // Check if properly started the recording before trying to stop it
    if (this.isRecorded && this.recording && this.recording.recordingId) {
      if (!this._stopRecordingEventFired) {
        this._sendStopShareEvent();
      }

      try {
        await this.mcs.stopRecording(this.presenterMCSUserId, this.recording.recordingId);
      } catch (error) {
        // Logging it in case it still happens, but recording should be stopped
        // if it errors out inside mcs-core or if we call mcs.leave for this user
        // so it'll always be stopped. If anything pops here, probably related
        // to it already being stopped or it wasn't started in the first place
        Logger.warn(LOG_PREFIX, `Stop recording MAY have failed for presenter ${this.presenterMCSUserId}`, {
          ...this._getFullPresenterLogMetadata(this._connectionId), error,
          recordingId: this.recording.recordingId
        });
      }
    }
  }

  async _releaseContentFloorIfNeeded () {
    try {
      const currentFloor = await this._fetchContentFloor(this._voiceBridge);
      if (currentFloor && (currentFloor.mediaId === this._presenterEndpoint
        || currentFloor.mediaSessionId === this._presenterEndpoint)) {
        await this.mcs.releaseContentFloor(this._voiceBridge, this._presenterEndpoint);
      }
      return currentFloor;
    } catch (error) {
      Logger.error(LOG_PREFIX, `Content floor release failed for room ${this._voiceBridge}`,
        { ...this._getPartialLogMetadata(), error });
    }
  }

  stopViewer (id) {
    const viewerUser = this._viewerUsers[id];
    if (viewerUser == null) {
      // User doesn't exist. Probably a stop request glare
      delete this._viewersCandidatesQueue[id];
      delete this._viewerEndpoints[id];
      return Promise.resolve();
    }

    const { userId } = viewerUser;
    const viewerMediaId = this._viewerEndpoints[id];
    Logger.info(LOG_PREFIX, `Stopping screenshare viewer ${userId}`,
      this._getFullViewerLogMetadata(id));

    if (viewerMediaId) {
      return this.mcs.unsubscribe(userId, viewerMediaId)
        .then(() => {
          Logger.debug(LOG_PREFIX, `Screenshare viewer ${userId} stopped`,
            this._getFullViewerLogMetadata(id));
          delete this._viewersCandidatesQueue[id];
          delete this._viewerEndpoints[id];
          delete this._viewerUsers[id];
        })
        .catch(error => {
          Logger.error(LOG_PREFIX, `Viewer unsubscribe failed for ${userId} due to ${error.message}`,
            { ...this._getFullViewerLogMetadata(id), error });
          delete this._viewersCandidatesQueue[id];
          delete this._viewerEndpoints[id];
          delete this._viewerUsers[id];
        });
    } else {
      Logger.warn(LOG_PREFIX, `Screenshare viewer ${userId} media ID not found, probably already released`,
        this._getFullViewerLogMetadata(id));
      return Promise.resolve();
    }
  }

  _stopAllViewers () {
    Object.keys(this._viewerUsers).forEach(async connectionId => {
      await this.stopViewer(connectionId);
    });
  }

  _stopRtmpBroadcast (meetingId) {
    return new Promise((resolve, reject) => {
      if (!SCREENSHARE_SERVER_AKKA_BROADCAST) return resolve();
      const timestamp = Math.floor(new Date());
      const dsrstom = Messaging.generateScreenshareRTMPBroadcastStoppedEvent2x(this._voiceBridge,
        this._voiceBridge, this._streamUrl, this._vw, this._vh, timestamp);
      this.bbbGW.publish(dsrstom, C.TO_AKKA_APPS);
      Logger.info(LOG_PREFIX, `Sent stopRtmpBroadcast for ${meetingId}`,
        this._getPartialLogMetadata());
      resolve();
    });
  }

  _notifyScreenshareEndToBBB () {
    return new Promise(async (resolve, reject) => {
      try {
        const shouldHandleRtmpBridge = await this.bbbGW.isChannelAvailable(C.TO_BBB_TRANSCODE_SYSTEM_CHAN) && ENABLE_SCREENSHARE_FLASH_BRIDGE;
        const strm = Messaging.generateStopTranscoderRequestMessage(this._meetingId, this._meetingId);
        // Either the transcoder is not available or screensharing couldn't be
        // correctly started
        if (this._status != C.MEDIA_STARTED || !shouldHandleRtmpBridge) {
          this._stopRtmpBroadcast(this._meetingId);
          return resolve();
        }
        if (shouldHandleRtmpBridge) {
          // Interoperability: capturing 1.1 stop_transcoder_reply messages
          this.bbbGW.once(C.STOP_TRANSCODER_REPLY+this._meetingId, async (payload) => {
            const meetingId = payload[C.MEETING_ID];
            await this._stopRtmpBroadcast(meetingId);
            return resolve();
          });

          // Capturing stop transcoder responses from the 2x model
          this.bbbGW.once(C.STOP_TRANSCODER_RESP_2x+this._meetingId, async (payload) => {
            const meetingId = payload[C.MEETING_ID_2x];
            await this._stopRtmpBroadcast(meetingId);
            return resolve();
          });

          this.bbbGW.publish(strm, C.TO_BBB_TRANSCODE_SYSTEM_CHAN);
        }
      } catch (error) {
        Logger.error(LOG_PREFIX, `CRITICAL: failed to send stopRtmpBroadcast`,
          { ...this._getFullPresenterLogMetadata(this._connectionId), error });
        // Resolve anyways. This is an unrecoverable error that should NEVER happen
        resolve();
      }
    });
  }

  stop () {
    return new Promise(async (resolve, reject) => {
      this.mcs.removeListener(C.MCS_DISCONNECTED, this.handleMCSCoreDisconnection);
      // This is a trailing stop request. Media is already being stopped or wasn
      // stopped, so early exit.
      if (this._status === C.MEDIA_STOPPED) {
        return resolve();
      }
      // Set this right away to avoid trailing stops
      this._status = C.MEDIA_STOPPED;
      // Stop the recording procedures if needed.
      this._stopRecording();
      // Send stopRtmpBroadcast message to akka-apps
      await this._notifyScreenshareEndToBBB();
      // Check if the presenter user ID is set. If it is, it means this has
      // been started through this process, so clean things up. If it isn't
      // it means this is a viewer-only session and content has been started
      // externally; so don't try to clean presenter stuff here because that's
      // the job of who started it.
      if (this.presenterMCSUserId) {
        if (this._presenterEndpoint) {
          await this._releaseContentFloorIfNeeded();
          try {
            await this.mcs.unpublish(this.presenterMCSUserId, this._presenterEndpoint);
          } catch (error) {
            Logger.error(LOG_PREFIX, `Unpublish failed for presenter ${this.presenterMCSUserId} due to ${error.message}`,
              { ...this._getFullPresenterLogMetadata(this._connectionId), error });
          }
        }

        if (this._ffmpegEndpoint) {
          try {
            await this.mcs.unsubscribe(this.presenterMCSUserId, this._ffmpegEndpoint);
            this._ffmpegEndpoint = null;
          } catch (error) {
            Logger.error(LOG_PREFIX, `RTP relay unsubscribe failed for presenter's ${this.presenterMCSUserId} due to ${error.message}`,
              { ...this._getFullPresenterLogMetadata(this._connectionId), error });
            this._ffmpegEndpoint = null;
          }
        }
      }

      this._stopAllViewers();
      delete sources[this._presenterEndpoint];
      this._presenterEndpoint = null;
      this._candidatesQueue = null;
      return resolve();
    });
  }
};
