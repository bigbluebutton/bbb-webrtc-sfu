/*
 * Lucas Fialho Zawacki
 * Paulo Renato Lanzarin
 * (C) Copyright 2017 Bigbluebutton
 *
 */

'use strict'

const C = require('../bbb/messages/Constants');
const MediaHandler = require('../media-handler');
const Utils = require('../utils/Utils.js');
const Messaging = require('../bbb/messages/Messaging');
const Logger = require('../utils/Logger');
const BaseProvider = require('../base/BaseProvider');
const config = require('config');
const localIpAddress = config.get('localIpAddress');
const EventEmitter = require('events').EventEmitter;
const SHOULD_RECORD = config.get('recordScreenSharing');
const KEYFRAME_INTERVAL = config.get('screenshareKeyframeInterval');
const ENABLE_SCREENSHARE_FLASH_BRIDGE = config.has('screenshareEnableFlashRTPBridge')
  ? config.get('screenshareEnableFlashRTPBridge')
  : false;
const DEFAULT_MEDIA_SPECS = config.get('conference-media-specs');
const SUBSCRIBER_SPEC_SLAVE = config.has('videoSubscriberSpecSlave')
  ? config.get('videoSubscriberSpecSlave')
  : false;
const KURENTO_REMB_PARAMS = config.util.cloneDeep(config.get('kurentoRembParams'));

const LOG_PREFIX = "[screenshare]";

// Global MCS endpoints mapping. These hashes maps IDs generated by the mcs-core
// lib to the ones generate in the ScreenshareManager
let sources = {};
let rtpEndpoints = {};

module.exports = class Screenshare extends BaseProvider {
  constructor(id, bbbGW, voiceBridge, userId, vh, vw, meetingId, mcs) {
    super(bbbGW);
    this.sfuApp = C.SCREENSHARE_APP;
    this.mcs = mcs;
    this.presenterMCSUserId;
    this.userId = userId;
    this._connectionId = id;
    this._presenterEndpoint = null;
    this._ffmpegEndpoint = null;
    this._voiceBridge = voiceBridge;
    this._meetingId = meetingId;
    this._streamUrl = "";
    this._vw = vw;
    this._vh = vh;
    this._presenterCandidatesQueue = [];
    this._viewerUsers = {};
    this._viewerEndpoints = [];
    this._viewersCandidatesQueue = [];
    this._status = C.MEDIA_STOPPED;
    this._rtmpBroadcastStarted = false;
    this.recording = {};
    this.isRecorded = false;
    this._recordingSubPath = 'screenshare';
    this._startRecordingEventFired = false;
    this._stopRecordingEventFired = false;
  }

  async onIceCandidate (candidate, role, userId, connectionId) {
    Logger.debug(LOG_PREFIX, "onIceCandidate", role, userId, candidate);
    switch (role) {
      case C.SEND_ROLE:
        if (this._presenterEndpoint) {
          try {
            this.flushCandidatesQueue(this.mcs, [...this._presenterCandidatesQueue], this._presenterEndpoint);
            this._presenterCandidatesQueue = [];

            await this.mcs.addIceCandidate(this._presenterEndpoint, candidate);
          } catch (err) {
            this._handleError(LOG_PREFIX, err, role, userId);
          }
        } else {
          Logger.debug(LOG_PREFIX, "Pushing ICE candidate to presenter queue");
          this._presenterCandidatesQueue.push(candidate);
        }
      case C.RECV_ROLE:
        let endpoint = this._viewerEndpoints[connectionId];
        if (endpoint) {
          try {
            this.flushCandidatesQueue(this.mcs, [...this._viewersCandidatesQueue[connectionId]], endpoint);
            this._viewersCandidatesQueue[connectionId] = [];

            await this.mcs.addIceCandidate(endpoint, candidate);
          } catch (err) {
            this._handleError(LOG_PREFIX, err, role, userId);
          }
        } else {
          this._viewersCandidatesQueue[connectionId] = [];
          Logger.debug(LOG_PREFIX, "Pushing ICE candidate to viewer queue", userId);
          this._viewersCandidatesQueue[connectionId].push(candidate);
        }
        break;
      default:
        Logger.warn(LOG_PREFIX, "Unknown role", role);
      }
  }

  _mediaStateRTP (event, endpoint) {
    const { mediaId, state } = event;
    const { name, details = null } = state;

    if (mediaId !== endpoint) {
      return;
    }

    switch (name) {
      case "MediaStateChanged":
        break;

      case "MediaFlowOutStateChange":
        Logger.info(LOG_PREFIX, "Session with media", mediaId, "received state", state);
        break;

      case "MediaFlowInStateChange":
        Logger.info(LOG_PREFIX, "Session with media", mediaId, "received state", state);
        if (details === 'FLOWING') {
          this._onRtpMediaFlowing();
        }
        else {
          this._onRtpMediaNotFlowing();
        }
        break;

      default: Logger.warn(LOG_PREFIX, "Unrecognized event", event);
    }
  }

  _onMCSIceCandidate (event, connectionId, endpoint) {
    const { mediaId, candidate } = event;

    if (mediaId !== endpoint) {
      return;
    }

    Logger.debug(LOG_PREFIX, 'Received ICE candidate from mcs-core for media session', mediaId, '=>', candidate, "for connection", connectionId);

    this.bbbGW.publish(JSON.stringify({
      connectionId,
      type: C.SCREENSHARE_APP,
      id : 'iceCandidate',
      cameraId: this._connectionId,
      candidate : candidate
    }), C.FROM_SCREENSHARE);

  }

  _mediaStateWebRTC (event, endpoint) {
    const { mediaId , state } = event;
    const { name, details } = state;

    if (mediaId !== endpoint) {
      return;
    }

    switch (name) {
      case "MediaStateChanged":
        break;
      case "MediaFlowOutStateChange":
      case "MediaFlowInStateChange":
        Logger.info(LOG_PREFIX, `WebRTC screenshare media ${mediaId} of ${this._voiceBridge} received media state event`,  { mediaStateEvent: state});
        if (!ENABLE_SCREENSHARE_FLASH_BRIDGE) {
          if (details === 'FLOWING') {
            this._onWebRTCMediaFlowing();
          }
          else {
            this._onWebRTCMediaNotFlowing();
          }
        }
        break;

      case C.MEDIA_SERVER_OFFLINE:
        Logger.error(LOG_PREFIX, "Screenshare provider received MEDIA_SERVER_OFFLINE event", event);
        this.emit(C.MEDIA_SERVER_OFFLINE, event);
        break;


      default: Logger.warn(LOG_PREFIX, "Unrecognized event", event);
    }
  }

  _mediaStateRecording (event, endpoint) {
    const { mediaId , state } = event;
    const { name, details } = state;

    if (mediaId !== endpoint) {
      return;
    }

    switch (name) {
      case "MediaStateChanged":
        break;
      case "MediaFlowOutStateChange":
      case "MediaFlowInStateChange":
        Logger.info(LOG_PREFIX, `Recording media ${endpoint} of ${this._voiceBridge} received media state event`, { mediaStateEvent: state })
        if (details === 'NOT_FLOWING' && this.status !== C.MEDIA_PAUSED) {
          Logger.warn(LOG_PREFIX, `Recording media ${endpoint} of ${this._voiceBridge} STOPPED FLOWING!`);
        } else if (details === 'FLOWING') {
          if (!this._startRecordingEventFired) {
            const { timestampHR, timestampUTC } = state;
            this.sendStartShareEvent(timestampHR, timestampUTC);
          }
        }
        break;

      default: Logger.trace(LOG_PREFIX, "Unhandled recording event", event);
    }
  }


  async startRecording() {
    return new Promise(async (resolve, reject) => {
      try {
        const contentCodec = DEFAULT_MEDIA_SPECS.codec_video_content;
        const recordingProfile = (contentCodec === 'VP8' || contentCodec === 'ANY')
          ? C.RECORDING_PROFILE_WEBM
          : C.RECORDING_PROFILE_MKV;
        const format = (contentCodec === 'VP8' || contentCodec === 'ANY')
          ? C.RECORDING_FORMAT_WEBM
          : C.RECORDING_FORMAT_MKV;
        const recordingPath = this.getRecordingPath(
          this._meetingId,
          this._recordingSubPath,
          this._voiceBridge,
          format
        );
        const recordingId = await this.mcs.startRecording(
          this.presenterMCSUserId,
          this._presenterEndpoint,
          recordingPath,
          { recordingProfile, ignoreThresholds: true }
        );
        this.recording = { recordingId, filename: recordingPath };
        this.mcs.onEvent(C.MEDIA_STATE, this.recording.recordingId, (event) => {
          this._mediaStateRecording(event, this.recording.recordingId);
        });
        resolve(this.recording);
      } catch (err) {
        reject(this._handleError(LOG_PREFIX, err));
      }
    });
  }

  sendStartShareEvent (timestampHR, timestampUTC) {
    const shareEvent = Messaging.generateWebRTCShareEvent('StartWebRTCDesktopShareEvent', this._meetingId, this.recording.filename, timestampHR, timestampUTC);
    this.bbbGW.writeMeetingKey(this._meetingId, shareEvent, function(error) {
      if (error) {
        Logger.warn(LOG_PREFIX, 'Error writing START share event error', error);
      }
      this._startRecordingEventFired = true;
    });
  }


  start (sessionId, connectionId, sdpOffer, bbbUserId, role, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      this._status = C.MEDIA_STARTING;
      // Probe akka-apps to see if this is to be recorded
      if (SHOULD_RECORD && role === C.SEND_ROLE) {
        this.isRecorded = await this.probeForRecordingStatus(this._meetingId, bbbUserId);
      }

      Logger.info(LOG_PREFIX, "Starting session", this._voiceBridge + '-' + role);

      if (role === C.RECV_ROLE) {
        try {
          const sdpAnswer = await this._startViewer(connectionId, this._voiceBridge, sdpOffer, bbbUserId, this._presenterEndpoint, bbbUserName)
          return resolve(sdpAnswer);
        }
        catch (err) {
          return reject(this._handleError(LOG_PREFIX, err, role, bbbUserId));
        }
      }

      if (role === C.SEND_ROLE) {
        try {
          const sdpAnswer = await this._startPresenter(sdpOffer, bbbUserId, bbbUserName);
          return resolve(sdpAnswer);
        }
        catch (err) {
          return reject(this._handleError(LOG_PREFIX, err, role, bbbUserId));
        }
      }
    });
  }

  _startPresenter (sdpOffer, userId, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      try {
        try {
          this.presenterMCSUserId = await this.mcs.join(this._voiceBridge, 'SFU', { userId, name: bbbUserName });
          Logger.info(LOG_PREFIX, "MCS Join for", this._connectionId, "returned", this.presenterMCSUserId);
        }
        catch (error) {
          Logger.error(LOG_PREFIX, "MCS Join returned error =>", error);
          return reject(this._handleError(LOG_PREFIX, error, role, userId));
        }

        const presenterSdpAnswer = await this._publishWebRTCStream(sdpOffer);
        await this.mcs.setContentFloor(this._voiceBridge, this._presenterEndpoint);

        resolve(presenterSdpAnswer);
      }
      catch (err) {
        Logger.error(LOG_PREFIX, "MCS publish returned error =>", err);
        reject(this._handleError(LOG_PREFIX, err));
      }

      if (ENABLE_SCREENSHARE_FLASH_BRIDGE) {
        try {
          await this._upstartRTPStream();
        } catch (e) {
          Logger.error(`${LOG_PREFIX} Screenshare RTP-RTMP bridge could not be started at ${this._voiceBridge}`, e)
        }
      }
    });
  }

  async _publishWebRTCStream (descriptor) {
    try {
      // Get the REMB spec to be used. Screenshare uses the default mixed in with
      // the default spec bitrate. Fetching bitrate by the VP8 codec is just an
      // arbitrary choice that makes no difference.
      // The media specs format isn't flexible enough, so that's what we have
      const kurentoRembParams = { ...KURENTO_REMB_PARAMS };
      kurentoRembParams.rembOnConnect = DEFAULT_MEDIA_SPECS.VP8.as_content;
      const options = {
        descriptor,
        name: this._assembleStreamName('publish', this.userId, this._voiceBridge),
        mediaProfile: 'content',
        kurentoRembParams,
      };

      const { mediaId, answer } = await this.mcs.publish(this.presenterMCSUserId, this._voiceBridge, C.WEBRTC, options);
      this._presenterEndpoint = mediaId;

      this.mcs.onEvent(C.MEDIA_STATE, this._presenterEndpoint, (event) => {
        this._mediaStateWebRTC(event, this._presenterEndpoint)
      });

      this.mcs.onEvent(C.MEDIA_STATE_ICE, this._presenterEndpoint, (event) => {
        this._onMCSIceCandidate(event, this._connectionId, this._presenterEndpoint);
      });

      sources[this._voiceBridge] = this._presenterEndpoint;
      const presenterSdpAnswer = answer;
      this.flushCandidatesQueue(this.mcs, [...this._presenterCandidatesQueue], this._presenterEndpoint);
      this._presenterCandidatesQueue = [];

      Logger.info(LOG_PREFIX, "MCS publish for user", this.presenterMCSUserId, "returned", this._presenterEndpoint);
      return presenterSdpAnswer;
    }
    catch (err) {
      throw err;
    }
  }

  async _fetchContentFloor () {
    try {
      const { floor } = await this.mcs.getContentFloor(this._voiceBridge);
      Logger.debug(LOG_PREFIX, `Content floor for ${this._voiceBridge} is ${floor}`);
      return floor;
    } catch (e) {
      throw e;
    }
  }

  async _upstartRTPStream () {
    try {
      const sendVideoPort = MediaHandler.getVideoPort();
      const rtpSdpOffer = MediaHandler.generateVideoSdp(localIpAddress, sendVideoPort);
      const options = {
        descriptor: rtpSdpOffer,
        keyframeInterval: KEYFRAME_INTERVAL,
        mediaProfile: 'content'
      }

      if (this._presenterEndpoint == null) {
        const floor = await this._fetchContentFloor();
        this._presenterEndpoint = floor? floor.mediaId : null
      }

      const { mediaId, answer } = await this.mcs.subscribe(this.presenterMCSUserId,
        this._presenterEndpoint, C.RTP, options);

      this._ffmpegEndpoint = mediaId;
      rtpEndpoints[this._voiceBridge] = this._ffmpegEndpoint;

      const recvVideoPort = answer.match(/m=video\s(\d*)/)[1];
      const ipRegex = /(IP4\s)([0-9.]*)/g;
      const mediaServerIp = ipRegex.exec(answer)[2];
      this._rtpParams = MediaHandler.generateTranscoderParams(mediaServerIp, localIpAddress,
          sendVideoPort, recvVideoPort, this._meetingId, "stream_type_video", C.RTP_TO_RTMP, "copy", this.userId, this._voiceBridge);

      this.mcs.onEvent(C.MEDIA_STATE, this._ffmpegEndpoint, (event) => {
        this._mediaStateRTP(event, this._ffmpegEndpoint);
      });

      Logger.info(LOG_PREFIX, "MCS subscribe for user", this.presenterMCSUserId, "returned", this._ffmpegEndpoint);
    } catch (err) {
      throw err;
    }
  }

  _startViewer(connectionId, voiceBridge, sdpOffer, userId, presenterEndpoint, bbbUserName) {
    return new Promise(async (resolve, reject) => {
      Logger.info(LOG_PREFIX, `Starting viewer ${userId} for voiceBridge ${this._voiceBridge}`);
      let sdpAnswer, mcsUserId;

      this._viewersCandidatesQueue[connectionId] = [];
      try {
        mcsUserId = await this.mcs.join(this._voiceBridge, 'SFU', { userId, name: bbbUserName });
        this._viewerUsers[userId] = { userId, connectionId };
        Logger.info(LOG_PREFIX, "MCS Join for", connectionId, "returned", mcsUserId);
      }
      catch (error) {
        Logger.error(LOG_PREFIX, "MCS Join returned error =>", error);
        return reject(this._handleError(LOG_PREFIX, error, role, userId));
      }

      try {
        // Get the REMB spec to be used. Screenshare uses the default mixed in with
        // the default spec bitrate. Fetching bitrate by the VP8 codec is just an
        // arbitrary choice that makes no difference.
        // The media specs format isn't flexible enough, so that's what we have
        const kurentoRembParams = { ...KURENTO_REMB_PARAMS };
        kurentoRembParams.rembOnConnect = DEFAULT_MEDIA_SPECS.VP8.as_content;
        const options = {
          descriptor: sdpOffer,
          name: this._assembleStreamName('subscribe', userId, this._voiceBridge),
          mediaProfile: 'content',
          mediaSpecSlave: SUBSCRIBER_SPEC_SLAVE,
          kurentoRembParams,
        }

        if (this._presenterEndpoint == null) {
          const floor = await this._fetchContentFloor();
          this._presenterEndpoint = floor? floor.mediaId : null
        }

        const { mediaId, answer } = await this.mcs.subscribe(mcsUserId,
          this._presenterEndpoint, C.WEBRTC, options);

        this._viewerEndpoints[connectionId] = mediaId;
        sdpAnswer = answer;

        this.flushCandidatesQueue(this.mcs, [...this._viewersCandidatesQueue[connectionId]], this._viewerEndpoints[connectionId]);
        this._viewersCandidatesQueue[connectionId] = [];

        this.mcs.onEvent(C.MEDIA_STATE, mediaId, (event) => {
          this._mediaStateWebRTC(event, mediaId)
        });

        this.mcs.onEvent(C.MEDIA_STATE_ICE, mediaId, (event) => {
          this._onMCSIceCandidate(event, connectionId, mediaId);
        });

        Logger.info(LOG_PREFIX, "MCS subscribe returned for user", mcsUserId, "returned", this._viewerEndpoints[connectionId], "at userId", userId);
        return resolve(sdpAnswer);
      }
      catch (err) {
        Logger.error(LOG_PREFIX, "MCS viewer subscribe returned error =>", err);
        return reject(this._handleError(LOG_PREFIX, err));
      }
    });
  }

  /* ======= STOP PROCEDURES ======= */

  _sendStopShareEvent () {
    const timestampUTC = Date.now()
    const timestampHR = Utils.hrTime();
    const shareEvent = Messaging.generateWebRTCShareEvent('StopWebRTCDesktopShareEvent', this._meetingId , this.recording.filename, timestampHR, timestampUTC);
    this.bbbGW.writeMeetingKey(this._meetingId, shareEvent, function(error) {
      if (error) {
        Logger.warn(LOG_PREFIX, 'Error writing STOP share event error', error);
      }
    });
    this._stopRecordingEventFired = true;
  }

  async _stopRecording () {
    // Check if properly started the recording before trying to stop it
    if (this.isRecorded && this.recording && this.recording.recordingId) {
      if (!this._stopRecordingEventFired) {
        this._sendStopShareEvent();
      }

      try {
        await this.mcs.stopRecording(this.presenterMCSUserId, this.recording.recordingId);
      } catch (error) {
        // Logging it in case it still happens, but recording should be stopped
        // if it errors out inside mcs-core or if we call mcs.leave for this user
        // so it'll always be stopped. If anything pops here, probably related
        // to it already being stopped or it wasn't started in the first place
        Logger.warn(LOG_PREFIX, `Stop recording failed for presenter ${this.presenterMCSUserId} at room ${this._voiceBridge}`, {
          roomId: this._voiceBridge, mediaId: this.recording.recordingId,
          userId: this.presenterMCSUserId, error,
        });
      }
    }
  }

  async _releaseContentFloorIfNeeded () {
    try {
      const currentFloor = await this._fetchContentFloor(this._voiceBridge);
      if (currentFloor && (currentFloor.mediaId === this._presenterEndpoint
        || currentFloor.mediaSessionId === this._presenterEndpoint)) {
        await this.mcs.releaseContentFloor(this._voiceBridge, this._presenterEndpoint);
      }
      return currentFloor;
    } catch (error) {
      Logger.error(LOG_PREFIX, `Content floor release failed for room ${this._voiceBridge}`, { roomId: this._voiceBridge, internalMeetingId: this._meetingId, error });
    }
  }

  async stopViewer(id) {
    const vuKey = Object.keys(this._viewerUsers).find(vuk => this._viewerUsers[vuk].connectionId === id);
    if (vuKey == null) {
      this._viewersCandidatesQueue[id] = null;
      this._viewerEndpoints[id] = null;
      return;
    }

    const { userId } = this._viewerUsers[vuKey];
    const viewerMediaId = this._viewerEndpoints[id];
    Logger.info(LOG_PREFIX, `Stopping screenshare viewer ${userId} at room ${this._voiceBridge}`, { userId, voiceBridge: this._voiceBridge });

    if (viewerMediaId) {
      try {
        await this.mcs.unsubscribe(userId, viewerMediaId);
      } catch (error) {
        Logger.error(LOG_PREFIX, `Viewer unsubscribe failed for ${userId} at room ${this._voiceBridge}`, {
          roomId: this._voiceBridge, mediaId: viewerMediaId,  userId, error,
          internalMeetingId: this._meetingId,
        });
      }
    }

    if (userId) {
      try {
        await this.mcs.leave(this._voiceBridge, userId);
      } catch (error) {
        Logger.error(LOG_PREFIX, `Viewer leave failed for ${userId} at room ${this._voiceBridge}`, {
          roomId: this._voiceBridge, mediaId: viewerMediaId,
          userId, error, internalMeetingId: this._meetingId,

        });
      }
    }

    this._viewersCandidatesQueue[id] = null;
    this._viewerEndpoints[id] = null;
    return;
  }

  _stopAllViewers () {
    Object.keys(this._viewerUsers).forEach(async vuk => {
      const { connectionId } = this._viewerUsers[vuk];
      this.stopViewer(connectionId);
    });
  }

  _stopRtmpBroadcast (meetingId) {
    return new Promise((resolve, reject) => {
      Logger.info(LOG_PREFIX, `Sending stopRtmpBroadcast at ${this._voiceBridge} `, {
        roomId: this._voiceBridge, internalMeetingId: this._meetingId, userId: this.presenterMCSUserId,
      });
      const timestamp = Math.floor(new Date());
      const dsrstom = Messaging.generateScreenshareRTMPBroadcastStoppedEvent2x(this._voiceBridge,
        this._voiceBridge, this._streamUrl, this._vw, this._vh, timestamp);
      this.bbbGW.publish(dsrstom, C.FROM_VOICE_CONF_SYSTEM_CHAN);
      resolve();
    });
  }

  _notifyScreenshareEndToBBB () {
    return new Promise(async (resolve, reject) => {
      try {
        const shouldHandleRtmpBridge = await this.bbbGW.isChannelAvailable(C.TO_BBB_TRANSCODE_SYSTEM_CHAN) && ENABLE_SCREENSHARE_FLASH_BRIDGE;
        const strm = Messaging.generateStopTranscoderRequestMessage(this._meetingId, this._meetingId);
        // Either the transcoder is not available or screensharing couldn't be
        // correctly started
        if (this._status != C.MEDIA_STARTED || !shouldHandleRtmpBridge) {
          this._stopRtmpBroadcast(this._meetingId);
          return resolve();
        }
        if (shouldHandleRtmpBridge) {
          // Interoperability: capturing 1.1 stop_transcoder_reply messages
          this.bbbGW.once(C.STOP_TRANSCODER_REPLY+this._meetingId, async (payload) => {
            const meetingId = payload[C.MEETING_ID];
            await this._stopRtmpBroadcast(meetingId);
            return resolve();
          });

          // Capturing stop transcoder responses from the 2x model
          this.bbbGW.once(C.STOP_TRANSCODER_RESP_2x+this._meetingId, async (payload) => {
            const meetingId = payload[C.MEETING_ID_2x];
            await this._stopRtmpBroadcast(meetingId);
            return resolve();
          });

          this.bbbGW.publish(strm, C.TO_BBB_TRANSCODE_SYSTEM_CHAN, function(error) {});
        }
      } catch (error) {
        Logger.error(LOG_PREFIX, `CRITICAL: failed to send stopRtmpBroadcast`, {
          roomId: this._voiceBridge, internalMeetingId: this._meetingId,
          mediaId: this._presenterEndpoint, userId: this.presenterMCSUserId, error,
          internalMeetingId: this._meetingId
        });
        // Resolve anyways. This is an unrecoverable error that should NEVER happen
        resolve();
      }
    });
  }

  stop () {
    return new Promise(async (resolve, reject) => {
      // This is a trailing stop request. Media is already being stopped or wasn
      // stopped, so early exit.
      if (this._status === C.MEDIA_STOPPED) {
        return resolve();
      }
      // Set this right away to avoid trailing stops
      this._status = C.MEDIA_STOPPED;
      // Stop the recording procedures if needed.
      this._stopRecording();
      // Send stopRtmpBroadcast message to akka-apps
      await this._notifyScreenshareEndToBBB();
      // Check if the presenter user ID is set. If it is, it means this has
      // been started through this process, so clean things up. If it isn't
      // it means this is a viewer-only session and content has been started
      // externally; so don't try to clean presenter stuff here because that's
      // the job of who started it.
      if (this.presenterMCSUserId) {
        if (this._presenterEndpoint) {
          await this._releaseContentFloorIfNeeded();
          try {
            await this.mcs.unpublish(this.presenterMCSUserId, this._presenterEndpoint);
          } catch (error) {
            Logger.error(LOG_PREFIX, `Unpublish failed for presenter ${this.presenterMCSUserId} at room ${this._voiceBridge}`, {
              roomId: this._voiceBridge, mediaId: this._presenterEndpoint,
              userId: this.presenterMCSUserId, error, internalMeetingId: this._meetingId,
            });
          }
        }

        if (this._ffmpegEndpoint) {
          try {
            await this.mcs.unsubscribe(this.presenterMCSUserId, this._ffmpegEndpoint);
            this._ffmpegEndpoint = null;
          } catch (error) {
            Logger.error(LOG_PREFIX, `RTP relay unsubscribe failed for presenter's ${this.presenterMCSUserId} at room ${this._voiceBridge}`, {
              roomId: this._voiceBridge, mediaId: this._ffmpegEndpoint,
              userId: this.presenterMCSUserId, error, internalMeetingId: this._meetingId,
            });
            this._ffmpegEndpoint = null;
          }
        }

        try {
          await this.mcs.leave(this._voiceBridge, this.presenterMCSUserId);
        } catch (error) {
          Logger.warn(LOG_PREFIX, `Leave failed for ${this.presenterMCSUserId} at ${this._voiceBridge}`, {
            roomId: this._voiceBridge, mediaId: this._ffmpegEndpoint,
            userId: this.presenterMCSUserId, error,
          });
        }
      }
      this._stopAllViewers();
      delete sources[this._presenterEndpoint];
      this._presenterEndpoint = null;
      this._candidatesQueue = null;
      return resolve();
    });
  }

  /* ======= MEDIA STATE PROCEDURES ======= */

  async _onWebRTCMediaFlowing () {
    if (!this._rtmpBroadcastStarted) {
      Logger.info(LOG_PREFIX, "WebRTC Media FLOWING for meeting", this._voiceBridge);
      // Checking if transcoder is avaiable; if so, transposes the stream to RTMP
      this._startRtmpBroadcast(this._meetingId);

      if (this._status != C.MEDIA_STARTED) {
        Logger.info(LOG_PREFIX, 'webRTC started flowing for meeting', this._voiceBridge);
        if (this.isRecorded) {
          this.startRecording();
        }
        this._status = C.MEDIA_STARTED;
      }
    }
  };

  async _onRtpMediaFlowing() {
    if (!this._rtmpBroadcastStarted) {
      Logger.info(LOG_PREFIX, "RTP Media FLOWING for meeting", this._voiceBridge);
      const shouldHandleRtmpBridge = await this.bbbGW.isChannelAvailable(C.TO_BBB_TRANSCODE_SYSTEM_CHAN) && ENABLE_SCREENSHARE_FLASH_BRIDGE;
      const strm = Messaging.generateStartTranscoderRequestMessage(this._meetingId, this._meetingId, this._rtpParams);

      // Checking if transcoder is avaiable; if so, transposes the stream to RTMP
      if (shouldHandleRtmpBridge) {
        // Interoperability: capturing 1.1 start_transcoder_reply messages
        this.bbbGW.once(C.START_TRANSCODER_REPLY+this._meetingId, (payload) => {
          let meetingId = payload[C.MEETING_ID];
          let output = payload["params"].output;
          this._startRtmpBroadcast(meetingId, output);
        });

        // Capturing stop transcoder responses from the 2x model
        this.bbbGW.once(C.START_TRANSCODER_RESP_2x+this._meetingId, (payload) => {
          let meetingId = payload[C.MEETING_ID_2x];
          let output = payload["params"].output;
          this._startRtmpBroadcast(meetingId, output);
        });

        this.bbbGW.publish(strm, C.TO_BBB_TRANSCODE_SYSTEM_CHAN, function(error) {});
      } else {
        // transcoder is not available, pure WebRTC environment
        this._startRtmpBroadcast(this._meetingId);
      }

      if (this._status != C.MEDIA_STARTED) {
        Logger.info(LOG_PREFIX, 'webRTC started flowing for meeting', this._voiceBridge);
        if (this.isRecorded) {
          this.startRecording();
        }
        this._status = C.MEDIA_STARTED;
      }
    }
  };

  _onWebRTCMediaNotFlowing () {
    // FIXME properly implement this when we have a client-side reconnection procedure
    Logger.warn(LOG_PREFIX, "TODO WebRTC source NOT_FLOWING in meeting", this._voiceBridge);
  }

  _onRtpMediaNotFlowing() {
    Logger.warn(LOG_PREFIX, "TODO RTP NOT_FLOWING");
  }


  _startRtmpBroadcast (meetingId, output) {
    Logger.info(LOG_PREFIX, "_startRtmpBroadcast for meeting", + meetingId);
    const timestamp = Math.floor(new Date());

    // If output is defined, we're using a RTMP url for the flash bridge
    // Else just pass the WebRTC stream name
    if (output) {
      this._streamUrl = MediaHandler.generateStreamUrl(localIpAddress, meetingId, output);
    } else {
      this._streamUrl = this._presenterEndpoint;
    }

    let dsrbstam = Messaging.generateScreenshareRTMPBroadcastStartedEvent2x(this._voiceBridge,
      this._voiceBridge, this._streamUrl, this._vw, this._vh, timestamp);

    this.bbbGW.publish(dsrbstam, C.FROM_VOICE_CONF_SYSTEM_CHAN, function(error) {});
    this._rtmpBroadcastStarted = true;
  }

};
